# PIMPilot - Produktmanagement SaaS

## Overview
PIMPilot is a multi-tenant B2B SaaS platform designed to automate AI-powered product description and PIM metadata generation from supplier data. It primarily processes product data via CSV uploads for multiple business customers, ensuring strict data isolation. The platform leverages OpenAI's GPT-4o-mini for text generation and a custom Cheerio-based web scraper. Its core capabilities include a robust multi-tenant architecture, secure authentication, Stripe-based subscription management, real-time API call monitoring, dynamic AI prompting, and a sophisticated category-based template system. The project aims to streamline product information management and enhance e-commerce content creation.

## User Preferences
Keine spezifischen Pr√§ferenzen dokumentiert.

## System Architecture

### Technology Stack
- **Frontend**: React 18, TypeScript, Vite, shadcn/ui, Radix UI, Tailwind CSS
- **Backend**: Express.js, TypeScript
- **Database**: PostgreSQL (Helium Dev / Supabase Production) with Drizzle ORM
- **AI/ML**: OpenAI API (GPT-4o-mini for text generation, GPT-4o-mini Vision for image analysis)
- **Web Scraping**: Cheerio (Custom scraper service)
- **Authentication**: Supabase Auth (JWT-based)

### System Design
The application employs a modular subprompt architecture for specialized AI tasks, centrally orchestrated. A 3-layer category-based template system (Category Configuration, AI Generator, Template Renderer) facilitates automatic category recognition and dynamic AI prompt adaptation. Multi-tenancy is enforced server-side using `organization_id` foreign keys to ensure data isolation.

**Key Features**:
- **Multi-Tenant Architecture**: Ensures data isolation per organization.
- **User Authentication**: Supabase Auth with session management.
- **Subscription Management**: Stripe integration for tiered access and trials.
- **Usage Tracking**: Real-time API call monitoring with limit enforcement.
- **CSV Bulk Processing**: Upload and process product data for mass AI generation.
- **URL Web Scraper**: Custom Cheerio-based scraper with configurable CSS selectors, intelligent auto-recognition, table parsing, multi-URL scraping, automatic login, and session cookie capture.
- **AI Generation**: Automated product descriptions using OpenAI GPT-4o-mini, including AI-powered image analysis for color detection.
- **Project Management**: Organize generated products into projects.
- **Supplier Profiles**: Manage multiple suppliers with saved selectors.
- **Pixi ERP Integration**: Automated product comparison with Pixi ERP for identifying new vs. existing products, with intelligent matching and CSV export.
- **CSS Selector Verification System**: Workflow for testing and verifying supplier-specific CSS selectors with visual feedback.
- **Field Mapping Tool**: Visual Click-to-Connect interface for mapping scraped data or CSV columns to Brickfox CSV export fields, supporting custom transformations and reusable presets.

### UI/UX Decisions
The frontend utilizes React 18, TypeScript, Vite, shadcn/ui, Radix UI, and Tailwind CSS for a modern and responsive user experience. Standardized `Table`-components ensure consistent design and functionality across the platform, including features like sticky headers and hover effects.

## External Dependencies
- **OpenAI API**: For AI-driven text generation (GPT-4o-mini) and image analysis (GPT-4o-mini Vision).
- **Supabase**: Provides PostgreSQL database, multi-tenancy support, and authentication services.
- **Stripe**: Integrated for subscription management and payment processing.
- **Pixi ERP API**: Used for product inventory comparison and duplicate detection.
- **Greyhound SMTP**: E-mail sending for automated supplier requests via nodemailer (though currently facing connectivity issues from Replit).

## Recent Changes

### 2025-11-02: Moderne Pricing-Seite mit Gradient-Design üé®
**Feature**: Professionelle 2-Spalten Pricing-Seite mit PIMPilot-spezifischen Features.

**Implementierung**:
- **2-Tarife-System**: Professional (f√ºr Start-Ups/KMUs) + Enterprise (f√ºr gro√üe Unternehmen)
- **Gradient-Design**: Enterprise-Karte mit blau‚Üílila Hintergrund-Gradient
- **Gradient-Button**: Enterprise CTA mit blau‚Üílila‚Üípink Gradient (wie Vorlage)
- **PIMPilot-Features**: CSV Bulk-Import, URL Scraper, AI-Produktbeschreibungen, PDF Auto-Scraper, Pixi ERP-Integration, MediaMarkt-Formatierung
- **Responsive Design**: 2-Spalten auf Desktop, gestapelt auf Mobile
- **Professional-Features**: Bis zu 500 Produkte/Monat, Lieferanten-Verwaltung, Brickfox CSV-Export
- **Enterprise-Features**: Unbegrenzte Produktgenerierung, PDF Auto-Scraper, Pixi-Integration, pers√∂nlicher Support

**Design-Highlights**:
- Professional: Wei√üe Karte mit blauen Akzenten, einfacher blauer Button
- Enterprise: Gradient-Background (blue-50 ‚Üí purple-50), lila/pink Akzente, Gradient-Button
- Moderne Checkmarks mit farblich passenden Icons
- Shadow-Effekte und Hover-Transitions f√ºr professionellen Look

**Betroffene Dateien**:
- `client/src/pages/pricing.tsx` - Komplett neu gestaltet mit modernem 2-Spalten-Layout

### 2025-11-02: Multi-Tenant-Registrierung mit robuster Slug-Generierung üè¢
**Feature**: Standard B2B SaaS Registrierungsflow - jede Firma erstellt automatisch ihren eigenen Tenant bei Registrierung.

**Implementierung**:
- **Frontend**: Firmenname-Feld zur Registrierung hinzugef√ºgt (`companyName` required)
- **Backend**: Automatische Tenant-Erstellung bei Registrierung mit eindeutigem Slug
- **Slug-Generierung**: Robuste Konvertierung deutscher Umlaute (√§‚Üíae, √∂‚Üíoe, √º‚Üíue, √ü‚Üíss)
- **Kollisionserkennung**: Automatisches Suffix bei doppelten Slugs (z.B. "mueller-gmbh" ‚Üí "mueller-gmbh-2")
- **Fallback**: Leere Slugs fallen zur√ºck auf "company"
- **Webhook**: Dynamische Tenant-Zuweisung aus `user_metadata.tenant_id` (statt hardcodiert AkkuShop)
- **Admin-Logik**: Erster User eines neuen Tenants wird automatisch Admin (`isAdmin=true, role=admin`)
- **Backward Compatibility**: Legacy-Users ohne `tenant_id` fallen zur√ºck auf AkkuShop-Tenant

**Test-Ergebnisse**:
- ‚úÖ "B√§cker & K√∂che GmbH" ‚Üí slug: "baecker-koeche-gmbh"
- ‚úÖ "M√ºller GmbH" ‚Üí slug: "mueller-gmbh"
- ‚úÖ "M√ºller GmbH" (Duplikat) ‚Üí slug: "mueller-gmbh-2"

**Betroffene Dateien**:
- `client/src/pages/register.tsx` - Firmenname-Feld
- `shared/schema.ts` - RegisterUserSchema erweitert
- `server/routes-supabase.ts` - Tenant-Erstellung mit robuster Slug-Generierung
- `server/webhooks-supabase.ts` - Dynamische tenant_id aus user_metadata
- `server/supabase-storage.ts` - `getTenantBySlug()` Methode hinzugef√ºgt

### 2025-11-02: PDF-Parser EK-Spalten-Fix + VK-Berechnung korrigiert üí∞
**Bugfix**: PDF-Parser liest jetzt die korrekte "Netto EK"-Spalte aus und berechnet VK korrekt.

**Problem**: PDF-Parser las die **UE/VP-Spalte** (Lieferanten-Verkaufspreis) statt der **Netto-EK-Spalte**.
- Beispiel: Netto EK = 23,96‚Ç¨ ‚úì, UE/VP = 49,99‚Ç¨ ‚úó
- Parser nahm f√§lschlicherweise 49,99‚Ç¨ (den letzten Preis in der Zeile)

**L√∂sung**:
- **PDF-Parser**: Nimmt jetzt den **vorletzten Preis** (Netto-EK), nicht den letzten (UE/VP)
- **Fallback**: Bei nur einem Preis wird dieser genommen
- **VK-Formel**: **VK = (EK √ó 2) + 19%** = **EK √ó 2 √ó 1,19** = **EK √ó 2,38**
- **Rundung**: Ergebnis wird immer auf ,95 gerundet (z.B. 9,95, 16,95, 11,95)

**Beispiele**:
- PDF: Netto EK = 23,96‚Ç¨ ‚Üí System: **EK = 23,96‚Ç¨** (unver√§ndert) ‚Üí **VK = 56,95‚Ç¨**
- EK = 5,00‚Ç¨ ‚Üí VK = 5 √ó 2 √ó 1,19 = 11,90 ‚Üí **11,95‚Ç¨**
- EK = 7,00‚Ç¨ ‚Üí VK = 7 √ó 2 √ó 1,19 = 16,66 ‚Üí **16,95‚Ç¨**

**Betroffene Dateien**:
- `server/services/pdf-parser.ts` - EK-Extraktion aus PDF (vorletzter statt letzter Preis)
- `client/src/pages/url-scraper.tsx` - VK-Berechnungslogik (PDF-Import)
- `server/scraper-service.ts` - VK-Berechnungslogik (Scraping)

### 2025-11-02: Magento-Gallery-JSON-Parser f√ºr ANSMANN-Produkte üñºÔ∏è
**Feature**: Intelligente Extraktion aller Produktbilder aus Magento-JavaScript-Galerien (ANSMANN PIM).

**Problem**: ANSMANN verwendet Magento's Fotorama-Plugin, das Bilder dynamisch per JavaScript l√§dt. Cheerio (HTML-Parser) kann nur statisches HTML parsen und fand daher nur 1 Fallback-Bild statt ~10 Galerie-Bildern.

**L√∂sung**:
- **Magento-JSON-Parser**: Extrahiert Bilder aus `<script type="text/x-magento-init">` JSON-Config
- **Automatische Erkennung**: Aktiviert sich, wenn ‚â§1 Bild gefunden wurde (Fallback-Trigger)
- **Vollst√§ndige Galerie**: Extrahiert alle Bilder (`full`, `large`, `thumb` URLs) ohne JavaScript-Ausf√ºhrung
- **Kein Headless Browser**: Performante L√∂sung ohne Browser-Overhead (Puppeteer/Playwright)
- **Robustes Fallback**: Bei JSON-Parse-Fehler bleibt das statische Fallback-Bild erhalten

**Ergebnisse**:
- ‚úÖ **10 Bilder** pro ANSMANN-Produkt (statt 1)
- ‚úÖ Alle Bilder automatisch heruntergeladen und lokal gespeichert
- ‚úÖ Keine Performance-Einbu√üen durch Headless-Browser

**Betroffene Dateien**:
- `server/scraper-service.ts` - Magento-Gallery-JSON-Parser mit Fallback-Trigger

### 2025-11-02: Static-File-Server f√ºr Produktbilder üåê
**Feature**: Lokale Produktbilder werden als URLs bereitgestellt, damit sie im Browser angezeigt werden k√∂nnen.

**Implementierung**:
- **Express Static-Server**: Serviert Bilder aus `attached_assets/product_images/` unter `/product-images/`
- **URL-Umwandlung**: Lokale Pfade werden automatisch in Browser-URLs konvertiert
  - Pfad: `attached_assets/product_images/ANS15210039/bild_1.jpg`
  - URL: `/product-images/ANS15210039/bild_1.jpg`
- **CSV-Export**: "Lokale_Bildpfade" enth√§lt jetzt direkte URLs (z.B. `/product-images/ANS15210039/bild_1.jpg|/product-images/ANS15210039/bild_2.jpg`)
- **Browser-Kompatibilit√§t**: Alle Bilder k√∂nnen direkt im Browser ge√∂ffnet werden

**Betroffene Dateien**:
- `server/index.ts` - Static-File-Server-Endpoint
- `server/routes-supabase.ts` - URL-Umwandlung f√ºr `localImagePaths`

### 2025-11-02: Automatischer Bilder-Download beim Scraping üì•
**Feature**: Alle Produktbilder werden beim Scraping automatisch heruntergeladen und lokal gespeichert.

**Implementierung**:
- **Image-Download-Service**: L√§dt alle Bilder eines Produkts herunter (Array-Loop f√ºr mehrere URLs)
- **Lokale Speicherung**: Bilder werden in `attached_assets/product_images/{Artikelnummer}/` gespeichert
- **Dateinamen**: `bild_1.jpg`, `bild_2.jpg`, etc. (automatische Erkennung der Dateiendung)
- **Sicherheit**: Artikelnummer wird sanitiert, um Directory Traversal Attacken zu verhindern (Whitelist: `[A-Za-z0-9_-]`)
- **CSV-Export**: Neue Spalte "Lokale_Bildpfade" mit allen lokalen Pfaden (zus√§tzlich zu Bild_URLs)
- **Error-Handling**: Fortsetzung auch bei fehlgeschlagenen Downloads einzelner Bilder

**Betroffene Dateien**:
- `server/image-download-service.ts` - Download-Service mit Sicherheits-Sanitierung
- `server/routes-supabase.ts` - Automatischer Download nach Scraping
- `client/src/pages/url-scraper.tsx` - Empfang und Export von `localImagePaths`

### 2025-11-02: Bildergalerie f√ºr gescrapte Produkte üñºÔ∏è
**Feature**: Interaktive Bildergalerie zum Anzeigen aller gescrapten Produktbilder in voller Gr√∂√üe.

**Implementierung**:
- **Klickbare Thumbnails**: Hover-Effekt mit Eye-Icon, zeigt Bildanzahl an (z.B. "3 Bilder")
- **Vollbild-Galerie**: Dialog mit gro√üer Bildanzeige, Navigation zwischen Bildern mit Pfeiltasten
- **Thumbnail-Leiste**: Alle Bilder als Thumbnails unten, aktives Bild wird hervorgehoben
- **Bild-Z√§hler**: "1 / 5" Anzeige f√ºr aktuelle Position
- **URL-Kopieren**: Kopier-Button f√ºr direkte Bild-URL mit Toast-Best√§tigung
- **Error-Handling**: Fallback-Bilder bei Ladefehlern

**Betroffene Dateien**:
- `client/src/pages/url-scraper.tsx` - Bildergalerie-Dialog und State-Management

### 2025-11-02: Spaltenauswahl f√ºr CSV-Export (URL-Scraper)
**Feature**: CSV-Export mit individueller Spaltenauswahl.

**Implementierung**:
- **Spaltenauswahl-Dialog**: Checkboxen f√ºr alle 23 Export-Felder (Artikelnummer, Produktname, EAN, technische Daten, SEO-Felder, etc.)
- **"Alle ausw√§hlen" / "Alle abw√§hlen"**: Schnelle Massenauswahl f√ºr alle Spalten
- **Persistente Auswahl**: Spaltenauswahl bleibt w√§hrend der Session erhalten
- **Flexible Exports**: Nur ausgew√§hlte Spalten werden ins CSV exportiert (z.B. nur Basis-Daten ohne SEO)

**Betroffene Dateien**:
- `client/src/pages/url-scraper.tsx` - Spaltenauswahl-UI und Export-Logik

### 2025-11-02: CSV-Bulk-Tabelle mit standardisiertem Table-Component
**√Ñnderung**: Vorschau-Tabelle verwendet jetzt das gleiche `Table`-Component wie alle anderen Tabellen (einheitliches CI).

**Implementierung**:
- **Table-Component**: `Table`, `TableHeader`, `TableBody`, `TableRow`, `TableHead`, `TableCell` aus `@/components/ui/table`
- **Einheitliches Design**: Hover-Effekte, Border, Spacing werden automatisch vom Component gehandhabt
- **Sticky Headers**: Gleiche Funktionalit√§t wie in PDF-Scraper und URL-Scraper

**Betroffene Dateien**:
- `client/src/components/bulk-description-table.tsx` - Table-Component-Migration

### 2025-11-02: MediaMarkt V1 - Dynamische Produkttyp-Extraktion
**√Ñnderung**: Produkttyp wird dynamisch aus dem Produktnamen extrahiert (nicht hardcodiert).

**Implementierung**:
- **Dynamische Extraktion**: Findet W√∂rter mit Schl√ºsselw√∂rtern wie "lampe", "batterie", "akku", "ladeger√§t"
- **Direkt aus Produktname**: "Nitecore Chameleon CG7 - 2500 Lumen **Taschenlampe**" ‚Üí extrahiert "Taschenlampe"
- **MediaMarkt V1**: "Taschenlampe NCCG7" (Produkttyp + Modellcode, **OHNE Marke**)
- **Flexibel**: Funktioniert mit beliebigen Produkttypen, keine hardcodierte Liste

**Betroffene Dateien**:
- `client/src/pages/url-scraper.tsx` - `extractProductTypeFromName()` Funktion